{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Class Classification with Keras",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "EV5MleGQQbHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUPwMg4fggXi"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retriving dataset\n",
        "\n",
        "!gdown --id -q 1N_iNvJ8zXfCiSb5t3IqjH1JMDcHUEYnj\n",
        "data = pd.read_csv(\"Iris.csv\")"
      ],
      "metadata": {
        "id": "XLqQAdXbgkEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing output column\n",
        "\n",
        "dummies = pd.get_dummies(data[\"Species\"])\n",
        "data[\"Species\"] = dummies.values.tolist()"
      ],
      "metadata": {
        "id": "jXBhgi0huFN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffling data\n",
        "\n",
        "shuffled_data = data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "print(shuffled_data)"
      ],
      "metadata": {
        "id": "8ckXvkXotKvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting input and output\n",
        "\n",
        "X = shuffled_data.drop([\"Id\", \"Species\"], axis=1).values\n",
        "Y = np.vstack(shuffled_data[\"Species\"].tolist())"
      ],
      "metadata": {
        "id": "ui8wFh3oCXYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing input\n",
        "\n",
        "X = normalize(X, axis=0)"
      ],
      "metadata": {
        "id": "vUnLeMaKwqXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting training, validation and test sets\n",
        "\n",
        "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size = 0.25)"
      ],
      "metadata": {
        "id": "wHbsJfLQXz9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "79zisFiZQh1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(hidden_layers, activation, optimizer, learning_rate):  \n",
        "  model = Sequential()\n",
        "  model.add(Dense(h1, activation = activation, input_dim = 4))\n",
        "  for i in range(hidden_layers - 1):\n",
        "    model.add(Dense(h2, activation = activation))\n",
        "  model.add(Dense(3, activation = 'sigmoid'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  K.set_value(model.optimizer.learning_rate, learning_rate)\n",
        "  return model"
      ],
      "metadata": {
        "id": "_37gLN-JLgFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "  _, accuracy = model.evaluate(X_train, Y_train, verbose=0)\n",
        "  print('Training Accuracy: %.2f' % (accuracy*100))\n",
        "  _, accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
        "  print('Validation Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "UPzqAd1_x1bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model):\n",
        "  _, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  print('Test Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "axvGBZ8SyInw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "tISzjl2ZQ08l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "h1 = 100\n",
        "h2 = 100\n",
        "epochs = 50\n",
        "learning_rate = 0.1\n",
        "activation = \"relu\"\n",
        "optimizer = \"adam\""
      ],
      "metadata": {
        "id": "9LyQSVC2Q3xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = create_model(hidden_layers = 2, activation = activation, optimizer = optimizer, learning_rate = learning_rate)\n",
        "history = model1.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = epochs, batch_size = X_train.shape[0], verbose=0)"
      ],
      "metadata": {
        "id": "mScBfiW2Vxg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model1)\n",
        "test(model1)"
      ],
      "metadata": {
        "id": "C2wxEScFhILc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_err = history.history[\"loss\"]\n",
        "val_err = history.history[\"val_loss\"]\n",
        "\n",
        "fig_err = go.Figure()\n",
        "fig_err.add_trace(go.Scatter(x=list(range(len(train_err))), y=train_err, name=\"Training Error\", mode='lines+markers'))\n",
        "fig_err.add_trace(go.Scatter(x=list(range(len(val_err))), y=val_err, name=\"Validation Error\", mode='lines+markers'))\n",
        "fig_err.update_layout(title = f'Error vs Iterations',title_x=0.5, xaxis_title= \"Iterations\", yaxis_title=\"Error\")\n",
        "\n",
        "fig_err.show(renderer=\"svg\")"
      ],
      "metadata": {
        "id": "Q2447Q-enM7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "fig_acc = go.Figure()\n",
        "fig_acc.add_trace(go.Scatter(x=list(range(len(train_acc))), y=train_acc, name=\"Training Accuracy\", mode='lines+markers'))\n",
        "fig_acc.add_trace(go.Scatter(x=list(range(len(val_acc))), y=val_acc, name=\"Validation Accuracy\", mode='lines+markers'))\n",
        "fig_acc.update_layout(title = f'Accuracy vs Iterations',title_x=0.5, xaxis_title= \"Iterations\", yaxis_title=\"Accuracy\")\n",
        "\n",
        "fig_acc.show(renderer=\"svg\")"
      ],
      "metadata": {
        "id": "TgLIppwlZV61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "3pqOQ5_1_-8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "HXXzM0gKyd2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Number of Hidden Layers"
      ],
      "metadata": {
        "id": "-xIdsHqga_vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"2 Hidden Layers\")\n",
        "model2 = create_model(hidden_layers = 2, activation = \"relu\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "evaluate(model2)\n",
        "\n",
        "print(\"\\n4 Hidden Layers\")\n",
        "model3 = create_model(hidden_layers = 4, activation = \"relu\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "model3.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "evaluate(model3)\n",
        "\n",
        "print(\"\\n6 Hidden Layers\")\n",
        "model4 = create_model(hidden_layers = 6, activation = \"relu\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "model4.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "evaluate(model4)"
      ],
      "metadata": {
        "id": "ad7rXySG1eL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Activation Functions"
      ],
      "metadata": {
        "id": "KPScIHnQbJlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ReLU Activation\")\n",
        "\n",
        "model5 = create_model(hidden_layers = 6, activation = \"relu\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model5.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model5)\n",
        "print(f\"Execution Time: {t2 - t1}\")\n",
        "\n",
        "print(\"\\nSigmoid Activation\")\n",
        "model6 = create_model(hidden_layers = 6, activation = \"sigmoid\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model6.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model6)\n",
        "print(f\"Execution Time: {t2 - t1}\")\n",
        "\n",
        "print(\"\\nHyperbolic Tangent Activation\")\n",
        "model7 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model7.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model7)\n",
        "print(f\"Execution Time: {t2 - t1}\")"
      ],
      "metadata": {
        "id": "8lXNkoct881O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Optimizers"
      ],
      "metadata": {
        "id": "15dSgguUbOx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adam Optimizer\")\n",
        "model8 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model8.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model8)\n",
        "print(f\"Execution Time: {t2 - t1}\")\n",
        "\n",
        "print(\"\\nAdagrad Optimizer\")\n",
        "model9 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adagrad\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model9.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model9)\n",
        "print(f\"Execution Time: {t2 - t1}\")\n",
        "\n",
        "print(\"\\nAdadelta Optimizer\")\n",
        "model10 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adadelta\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model10.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model10)\n",
        "print(f\"Execution Time: {t2 - t1}\")"
      ],
      "metadata": {
        "id": "bvk0A9mf9j0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Learning Rates"
      ],
      "metadata": {
        "id": "K3YMHEChbSAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Learning Rate = 1\")\n",
        "model11 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adam\", learning_rate = 1)\n",
        "t1 = time.perf_counter()\n",
        "model11.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model11)\n",
        "print(f\"Execution Time: {t2 - t1}\")\n",
        "\n",
        "print(\"\\nLearning Rate = 0.1\")\n",
        "model12 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adam\", learning_rate = 0.1)\n",
        "t1 = time.perf_counter()\n",
        "model12.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model12)\n",
        "print(f\"Execution Time: {t2 - t1}\")\n",
        "\n",
        "print(\"\\nLearning Rate = 0.01\")\n",
        "model13 = create_model(hidden_layers = 6, activation = \"tanh\", optimizer = \"adam\", learning_rate = 0.01)\n",
        "t1 = time.perf_counter()\n",
        "model13.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 50, batch_size = X_train.shape[0], verbose=0)\n",
        "t2 = time.perf_counter()\n",
        "evaluate(model13)\n",
        "print(f\"Execution Time: {t2 - t1}\")"
      ],
      "metadata": {
        "id": "sXk3mjSm-SZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}