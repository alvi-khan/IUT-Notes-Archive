{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-3-VKYKCtHxt",
        "k83tAOYnv59r"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP7spxaBM4N6"
      },
      "source": [
        "#Simple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzRLPdpGj636"
      },
      "source": [
        "This is a very simple tutorial intended for the beginners to understand and implement Simple Linear Regression from the scratch. \n",
        "\n",
        "\n",
        "\n",
        "**Simple Linear Regression** is a great first machine learning algorithm to implement as it requires you to estimate properties from your training dataset, but is simple enough for beginners to understand. Linear regression is a prediction method that is more than 200 years old. In this tutorial, you will discover how to implement the simple linear regression algorithm from scratch in Python.\n",
        "\n",
        "After completing this tutorial you will know:<br>\n",
        "&#9632; How to estimate statistical quantities from training data.<br>\n",
        "&#9632; How to estimate linear regression coefficients from data.<br>\n",
        "&#9632; How to make predictions using linear regression for new data.<br>\n",
        "\n",
        "\n",
        "Linear regression assumes a **linear or straight line relationship between the input variables (X) and the single output variable (y).** More specifically, that output (y) can be calculated from a linear combination of the input variables (X). When there is a single input variable, the method is referred to as a simple linear regression.\n",
        "\n",
        "In simple linear regression we can use statistics on the training data to estimate the coefficients required by the model to make predictions on new data.\n",
        "\n",
        "The line for a simple linear regression model can be written as:\n",
        "\n",
        "$$ y = θ_0 + θ_1 \\times x $$\n",
        "where $θ_0$ and $θ_1$ are the coefficients we must estimate from the training data. Once the coefficients are known, we can use this equation to estimate \n",
        "output values for $y$ given new input examples of $x$. It requires that you calculate statistical properties from the data such as **mean, variance** and **covariance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMWmRb56kaiI"
      },
      "source": [
        "We will use a dataset to understand the relationship between the numbers of hours a student studies and the percentage of marks that student scores in an exam which demonstrate simple linear regression. The dataset involves **predicting the obtained percentage score of a student ($y$) given the total number of hourse s/he has studied ($x$).**\n",
        "\n",
        "**[Dataset can be found here.](https://drive.google.com/file/d/1HChTis2Kwhk-1EZC6yvJHx6vHBO_94Aq/view?usp=sharing)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-OZq8cvkcku"
      },
      "source": [
        "Let's load some basic python libraries that we will need over the course of this tutorial. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfpjHvdoiaQq"
      },
      "source": [
        "# library for manipulating the csv data\n",
        "import pandas as pd\n",
        "\n",
        "# library for scientific calculations on numbers + linear algebra\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# library for regular plot visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#library for responsive visualizations\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgzMISsKM_w7"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC9OGX2TnZjJ"
      },
      "source": [
        "**Downloading the Dataset**<br>\n",
        "Full Dataset Link: [https://drive.google.com/file/d/1HChTis2Kwhk-1EZC6yvJHx6vHBO_94Aq/view?usp=sharing](https://drive.google.com/file/d/1HChTis2Kwhk-1EZC6yvJHx6vHBO_94Aq/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4xuPIY4ncuP"
      },
      "source": [
        "!gdown --id 1HChTis2Kwhk-1EZC6yvJHx6vHBO_94Aq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W92-IYiJn63t"
      },
      "source": [
        "Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnVTBTnn-H1"
      },
      "source": [
        "data = pd.read_csv('/content/student_scores.csv')\n",
        "\n",
        "print(\"---Data Info---\")\n",
        "data.info()\n",
        "print(\"---Data Head---\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fjGxqRxdBlU"
      },
      "source": [
        "Dataset Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f321_NZ5dDPq"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqGL_TYRpZji"
      },
      "source": [
        "Let's have a look at the data itself. You can either use `matplotlib.pyplot` or `plotly` for visualization. The latter one produces responsive visualizations. Try hovering over the points on the graph to see the actual values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM6jHJyMqkfF"
      },
      "source": [
        "fig = px.scatter(x = data['Hours'], y=data['Scores'])\n",
        "fig.update_layout(title = 'Obtained Score Percentage vs Hours-Studied', title_x=0.5, \n",
        "                  xaxis_title= \"Number of Hours Studied\", yaxis_title=\"Obtained Percentage Score\", \n",
        "                  height = 500, width = 700)\n",
        "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTzrjAOTsTp8"
      },
      "source": [
        "**This tutorial is broken down into five parts:<br>**\n",
        "1. Calculate Mean and Variance.\n",
        "2. Calculate Covariance (X,Y).\n",
        "3. Estimate Coefficients.\n",
        "4. Make Predictions.\n",
        "5. Visual Comparison for Correctness.<br>\n",
        "\n",
        "These steps will give you the foundation you need to implement and train simple linear regression models for your own prediction problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8qZiFevsiYP"
      },
      "source": [
        "## 1. Calculate Mean and Variance.\n",
        "As said earlier, simple linear regression uses mean and variance of the given data. We will use `numpy` builtin functions to calculate them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx3TJc3tM03p"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtFJzgnqsaSg"
      },
      "source": [
        "print(data[\"Hours\"])\n",
        "print(data[\"Scores\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpMqVZKUsuM4"
      },
      "source": [
        "mean_x = np.mean(data[\"Hours\"])\n",
        "mean_y = np.mean(data[\"Scores\"])\n",
        "\n",
        "var_x = np.var(data[\"Hours\"])\n",
        "var_y = np.var(data[\"Scores\"])\n",
        "\n",
        "print('x stats: mean= %.3f   variance= %.3f' % (mean_x, var_x))\n",
        "print('y stats: mean= %.3f   variance= %.3f' % (mean_y, var_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3-VKYKCtHxt"
      },
      "source": [
        "## 2. Calculate Covariance.\n",
        "The covariance of two groups of numbers describes how those numbers change together. Covariance is a generalization of correlation. Correlation describes the relationship between two groups of numbers, whereas covariance can describe the relationship between two or more groups of numbers. It is calculated by the following formula. \n",
        "$$ Cov(X,Y) = \\frac{\\sum{(X_i - \\overline{X})}{(Y_j - \\overline{Y})}}{n-1} $$\n",
        "\n",
        "You can simply implement it by yourself or use builtin function `numpy.cov()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0rEab14tPic"
      },
      "source": [
        "# Calculate covariance between x and y\n",
        "def covariance(x, y):\n",
        "    mean_x = np.mean(x)\n",
        "    mean_y = np.mean(y)\n",
        "    covar = 0.0\n",
        "    for i in range(len(x)):\n",
        "        covar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "    return covar/(len(x)-1)\n",
        "\n",
        "cov_xy = covariance(data['Hours'], data['Scores'])\n",
        "\n",
        "print(f'Cov(X,Y): {cov_xy}')\n",
        "print(f'Covariance Using Built-In Function:\\n{np.cov(data[\"Hours\"], data[\"Scores\"])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k83tAOYnv59r"
      },
      "source": [
        "## 3. Estimate Coefficients\n",
        "We must estimate the values for two coefficients $θ_0$ & $θ_1$ in simple linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRNY-EOgv7Lq"
      },
      "source": [
        "θ_1 = cov_xy / var_x\n",
        "θ_0 = mean_y - θ_1 * mean_x\n",
        "\n",
        "print(f'Coefficents:\\n θ_0: {θ_0}  θ_1: {θ_1} ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqhYPJ21wtgd"
      },
      "source": [
        "## 4. Make Predictions\n",
        "The simple linear regression model is a line defined by coefficients estimated from training data. Once the coefficients are estimated, we can use them to make predictions. The equation to make predictions with a simple linear regression model is as follows:\n",
        "$$ \\hat{y} = θ_0 + θ_1 * x $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jGUL1ROwxYq"
      },
      "source": [
        "# Taking the values from the dataframe\n",
        "x = data['Hours'].values.copy()\n",
        "\n",
        "print(f'x: {x}')\n",
        "\n",
        "# Predicting the new data based on calculated coeffiecents. \n",
        "y_pred = θ_0 + θ_1 * x\n",
        "print(f'\\n\\ny_pred: {y_pred}')\n",
        "\n",
        "y = data['Scores'].values.copy()\n",
        "print(f'\\n\\ny: {y}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3jpOlnnxmFn"
      },
      "source": [
        "## 5. Visual Comparison for Correctness \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dh67Dwaxnil"
      },
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=data[\"Hours\"], y=data[\"Scores\"], name='train', mode='markers', marker_color='rgba(152, 0, 0, .8)'))\n",
        "fig.add_trace(go.Scatter(x=data[\"Hours\"], y=y_pred, name='prediction', mode='lines+markers', marker_color='rgba(0, 152, 0, .8)'))\n",
        "\n",
        "fig.update_layout(title = f'Obtained Score Percentage vs Hours-Studied\\n (visual comparison for correctness)',title_x=0.5, xaxis_title= \"Number of Hours Studied\", yaxis_title=\"Obtained Percentage Score\")\n",
        "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5OdT8NrPbH4"
      },
      "source": [
        "**<font color='red'>Wait, this is not the right way to do it!</font>**<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzsqUE7XPuzf"
      },
      "source": [
        "Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il-WZeeKPxpE"
      },
      "source": [
        "X = data.iloc[:,0].values\n",
        "Y = data.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRGXgPyQhs4"
      },
      "source": [
        "Splitting Training and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el3IfW-SQk7S"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqYEkyWfSIPb"
      },
      "source": [
        "Calculating co-efficients again! But this time only using the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJJ_9VuoSQG5"
      },
      "source": [
        "mean_x = np.mean(X_train)\n",
        "mean_y = np.mean(Y_train)\n",
        "\n",
        "var_x = np.var(X_train)\n",
        "var_y = np.var(Y_train)\n",
        "\n",
        "print('x stats: mean= %.3f   variance= %.3f' % (mean_x, var_x))\n",
        "print('y stats: mean= %.3f   variance= %.3f' % (mean_y, var_y))\n",
        "\n",
        "cov_xy = covariance(X_train, Y_train)\n",
        "θ_1 = cov_xy / var_x\n",
        "θ_0 = mean_y - b1 * mean_x\n",
        "\n",
        "print(f'Coefficents:\\n θ_0: {θ_0}  θ_1: {θ_1} ')\n",
        "\n",
        "print(f'\\n\\ny: {X}')\n",
        "\n",
        "# Predicting the new data based on calculated coeffiecents. \n",
        "y_pred = θ_0 + θ_1 * X\n",
        "print(f'\\n\\ny_pred: {y_pred}')\n",
        "\n",
        "print(f'\\n\\ny: {Y}')\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=X, y=Y, name='train', mode='markers', marker_color='rgba(152, 0, 0, .8)'))\n",
        "fig.add_trace(go.Scatter(x=X, y=y_pred, name='prediction', mode='lines+markers', marker_color='rgba(0, 152, 0, .8)'))\n",
        "\n",
        "fig.update_layout(title = f'Obtained Score Percentage vs Hours-Studied\\n (visual comparison for correctness after Train-Test Split)',title_x=0.5, xaxis_title= \"Number of Hours Studied\", yaxis_title=\"Obtained Percentage Score\")\n",
        "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOAKZjH3UnO3"
      },
      "source": [
        "Predicting only the test samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Ls_Tx6UqPX"
      },
      "source": [
        "y_pred = θ_0 + θ_1 * X_test\n",
        "print(f'\\n\\nY_Test: {Y_test}')\n",
        "print(f'\\n\\nY_Pred: {y_pred}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIVMSvsQpm9d"
      },
      "source": [
        "# Task 01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdS9SbefaYLb"
      },
      "source": [
        "## Calculating MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_tfHp9KYvvn"
      },
      "source": [
        "def calculate_mse(data, test):\n",
        "  differences = pow(data - test, 2)\n",
        "  mse = np.sum(differences) / test.size\n",
        "  return mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka5SAvWYcOfG"
      },
      "source": [
        "## Training Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu1zuF3mcKkf"
      },
      "source": [
        "training_output = θ_0 + θ_1 * X_train\n",
        "calculate_mse(training_output, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0gZrW62VD18"
      },
      "source": [
        "#Gradient Descent Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nX0Ky92WlpM"
      },
      "source": [
        " Now you are going to implement Gradient Descent Algorithm from the scratch. To understand how it works you will need some basic math and logical thinking. Gradient Descent can be used in different machine learning algorithms, including neural networks. For this lab, you are going to build it for a linear regression problem, because it’s easy to understand and visualize.\n",
        "\n",
        "### Linear Regression\n",
        "\n",
        "In order to fit the regression line, we tune two parameters: $slope (θ_1)$ and $intercept (θ_0).$ Once optimal parameters are found, we usually evaluate results with a  mean squared error $(MSE).$ We remember that smaller MSE — better. In other words, we are trying to minimize it.\n",
        "\n",
        "\n",
        "### Gradient Descent\n",
        "Minimization of the function is the exact task of the Gradient Descent algorithm. It takes parameters and tunes them till the local minimum is reached.\n",
        "\n",
        "Let’s break down the process in steps and explain what is actually going on under the hood:\n",
        "1. First, we take a function we would like to minimize, and very frequently it will be Mean Squared Errors function. \n",
        "2. We identify parameters, such as m and b in the regression function and we take partial derivatives of MSE with respect to these parameters. This is the most crucial and hardest part. Each derived function can tell which way we should tune parameters and by how much.\n",
        "2. We update parameters by iterating through our derived functions and gradually minimizing MSE. In this process, we use an additional parameter **learning rate** which helps us define the step we take towards updating parameters with each iteration. By setting a smaller learning rate we make sure our model wouldn’t jump over a minimum point of MSE and converge nicely.\n",
        "\n",
        "\n",
        "The formula of the Mean Squared Error MSE is as follows: \n",
        "$$ MSE = \\frac{1}{n}\\sum\\limits_{i=1}^n(y_{i} - \\hat{y})^2$$  where$$ \\hat{y} = θ_0 + θ_1x_i$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPnaDyPmcQsd"
      },
      "source": [
        "##Test Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO-bWf26cMFf"
      },
      "source": [
        "calculate_mse(y_pred, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nhkw1HyKliq"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xmEICB4XN6N"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def gradient_descent(X, y, lr=0.0001, epoch=12):\n",
        "  θ_1, θ_0 = 0.0, 0.0 # parameters\n",
        "  log, mse = [], [] # lists to store learning process\n",
        "  # GRADIENT DESCENT ALGORITHM\n",
        "  for i in range(epoch):\n",
        "    sumyhat = 0\n",
        "    sumxyhat = 0\n",
        "    # CALCULATE SUM PORTIONS; COULD HAVE VECTORISED HERE\n",
        "    for j in range(len(X)):\n",
        "      sumyhat += θ_0 + θ_1*X[j] - y[j]\n",
        "      sumxyhat += (θ_0 + θ_1*X[j] - y[j])*(X[j])\n",
        "    # CALCULATE AND UPDATE b1 AND b0\n",
        "    θ_1 -= lr*(1/len(X))*sumxyhat\n",
        "    θ_0 -= lr*(1/len(X))*sumyhat\n",
        "\n",
        "    # COULD HAVE ADDED THE CONDITION HERE\n",
        "    # BUT MATHEMATICALLY IT SEEMED THAT THE THRESHOLD VALUE WOULD BE DIFFICULT TO ACCURATELY PUT IN\n",
        "    # AND THE NUMBER OF EPOCHS CHOSEN HERE (20) OR EVEN 10 TIMES HIGHER IS MORE \n",
        "\n",
        "    # UPDATE LOGS AND MSES\n",
        "    log.append((θ_1, θ_0))\n",
        "    mse.append(mean_squared_error(y, (θ_1*X + θ_0)))\n",
        "\n",
        "    # TASK 2 BEGINS HERE:\n",
        "    # Add a condition to break the loop once the change in the error falls below 0.01\n",
        "\n",
        "    if (i != 0 and abs(mse[i] - mse[i - 1]) <= 0.01):\n",
        "      break\n",
        "    \n",
        "  return θ_1, θ_0, log, mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLV8efKQYCK4"
      },
      "source": [
        "θ_1, θ_0, log, mse = gradient_descent(X_train, Y_train , epoch = 2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMEBVhbUYP9F"
      },
      "source": [
        "log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgTnAyt0YRHn"
      },
      "source": [
        "y_pred = θ_0 + θ_1 * X\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=X, y=Y, name='train', mode='markers', marker_color='rgba(152, 0, 0, .8)'))\n",
        "fig.add_trace(go.Scatter(x=X, y=y_pred, name='prediction', mode='lines+markers', marker_color='rgba(0, 152, 0, .8)'))\n",
        "\n",
        "fig.update_layout(title = f'Obtained Score Percentage vs Hours-Studied\\n (visual comparison for correctness after Train-Test Split)',title_x=0.5, xaxis_title= \"Number of Hours Studied\", yaxis_title=\"Obtained Percentage Score\")\n",
        "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.show()\n",
        "\n",
        "y_pred = θ_0 + θ_1 * X_test\n",
        "print(f'\\n\\nY_Test: {Y_test}')\n",
        "print(f'\\n\\nY_Pred: {y_pred}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWPQEnMqK_Vh"
      },
      "source": [
        "#Task 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE6Gf_U5gGs3"
      },
      "source": [
        "def plot_mse(mse):\n",
        "  error_fig = go.Figure()\n",
        "  error_fig.add_trace(go.Scatter(x=list(range(len(mse))), y=mse, name='mse', mode='lines+markers', marker_color='rgba(0, 152, 0, .8)'))\n",
        "  \n",
        "  error_fig.update_layout(title = f'MSE vs Iterations',title_x=0.5, xaxis_title= \"Iterations\", yaxis_title=\"MSE\")\n",
        "  error_fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "  error_fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "\n",
        "  error_fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gENQRawGnOf7"
      },
      "source": [
        "plot_mse(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZCGo0lJZzwA"
      },
      "source": [
        "#Linear Regression with Scikit Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIh0XUhRZ-4Q"
      },
      "source": [
        "Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea-2oK4zaMj3"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnm77jBSbZpa"
      },
      "source": [
        "Reshaping the training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVH_5fS3bTSO"
      },
      "source": [
        "X_train = X_train.reshape(-1,1)\n",
        "X_test = X_test.reshape(-1,1)\n",
        "Y_train = Y_train.reshape(-1,1)\n",
        "Y_test = Y_test.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3oLHg_1aRiG"
      },
      "source": [
        "Training The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sVtC4DkaTVF"
      },
      "source": [
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD2xb9E_aXms"
      },
      "source": [
        "Printing $Intercept$ and $Slope$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atp-y5KGac8j"
      },
      "source": [
        "print(regressor.intercept_, regressor.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLjB_G8Pbws3"
      },
      "source": [
        "Making Predictions and visual comparison for correctness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NHqcUD-b29I"
      },
      "source": [
        "y_pred = regressor.predict(X.reshape(-1,1))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=X, y=Y, name='train', mode='markers', marker_color='rgba(152, 0, 0, .8)'))\n",
        "fig.add_trace(go.Scatter(x=X, y=y_pred.flatten(), name='prediction', mode='lines+markers', marker_color='rgba(0, 152, 0, .8)'))\n",
        "\n",
        "fig.update_layout(title = f'Obtained Score Percentage vs Hours-Studied\\n (visual comparison for correctness after Train-Test Split)',title_x=0.5, xaxis_title= \"Number of Hours Studied\", yaxis_title=\"Obtained Percentage Score\")\n",
        "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.show()\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "print(f'\\n\\nY_Test: {Y_test.flatten()}')\n",
        "print(f'\\n\\nY_Pred: {y_pred.flatten()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbpKt8BveR7-"
      },
      "source": [
        "#Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVyztri6eW2T"
      },
      "source": [
        "In the previous section we performed linear regression involving two variables. Almost all real world problems that you are going to encounter will have more than two variables. Linear regression involving multiple variables is called \"multiple linear regression\". The steps to perform multiple linear regression are almost similar to that of simple linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U4gO_inekQd"
      },
      "source": [
        "##Dataset\n",
        "we will use multiple linear regression to predict the gas consumptions (in millions of gallons) in 48 US states based upon gas taxes (in cents), per capita income (dollars), paved highways (in miles) and the proportion of population that has a drivers license.\n",
        "\n",
        "[Dataset can be downloaded from here.](https://drive.google.com/file/d/1lHJC6sb3ZQoWrrFQJq5zUVxFbQbLlqHH/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgqaFbQhf0so"
      },
      "source": [
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7nRkjuff2Uh"
      },
      "source": [
        "!gdown --id 1lHJC6sb3ZQoWrrFQJq5zUVxFbQbLlqHH\n",
        "data = pd.read_csv('/content/petrol_consumption.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcNi-NuPgUd9"
      },
      "source": [
        "X = data[['Petrol_tax', 'Average_income', 'Paved_Highways',\n",
        "       'Population_Driver_licence(%)']]\n",
        "Y = data['Petrol_Consumption']\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfGInWemhBOf"
      },
      "source": [
        "Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL3JRICOhDGg"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek_G0teAMnFQ"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP16boephKnG"
      },
      "source": [
        "Training the multiple linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l8nKkHjhPIS"
      },
      "source": [
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH9TuCqThbUt"
      },
      "source": [
        "Printing the coeficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzLYDSOthe8L"
      },
      "source": [
        "coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])\n",
        "coeff_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcXlY53PitSe"
      },
      "source": [
        "This means that for a unit increase in \"petrol_tax\", there is a decrease of 24.19 million gallons in gas consumption. Similarly, a unit increase in proportion of population with a drivers license results in an increase of 1.324 billion gallons of gas consumption. We can see that \"Average_income\" and \"Paved_Highways\" have a very little effect on the gas consumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlRG5lk9iz98"
      },
      "source": [
        "##Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGd2rozli3bn"
      },
      "source": [
        "Y_pred = regressor.predict(X_test)\n",
        "df = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}