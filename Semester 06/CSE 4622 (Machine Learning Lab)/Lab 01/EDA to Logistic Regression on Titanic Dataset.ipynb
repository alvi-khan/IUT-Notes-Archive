{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "02. EDA to Logistic Regression on Titanic Dataset.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6CsJAR-ysD5"
   },
   "source": [
    "- Let's do Exploratory data analysis on the [Titanic Dataset](https://www.kaggle.com/c/titanic/data) !\n",
    "- We'll use pandas , seaborn and matplotlib libraries of Python. \n",
    "- One way to bring the dataset here is to download from kaggle and upload here. Another way is to directly download in colab using an API token. [(reference)](https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VZrP0DOIvvoN"
   },
   "source": [
    "## Kaggle data to colab: https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/\n",
    "''' directly downloading from Kaggle using API. Remember to create kaggle.json file from you kaggle account. '''\n",
    "! pip install kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OqvgDJGax3GJ"
   },
   "source": [
    "!kaggle competitions download -c titanic # this API token was collected from the dataset website"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lClvmPJH0qeY"
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhTmSjAP05bk"
   },
   "source": [
    "- 11 features, need to predict whether the person 'Survived' or not."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QIlN4MYJyC30"
   },
   "source": [
    "# Let's load the train dataframe...\n",
    "train = pd.read_csv('/content/train.csv')\n",
    "train.head() # returns the first five rows"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_CN__VGyZNMA"
   },
   "source": [
    "train.head(10) # we can also define how many rows to show in head func."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gWyGsartZHT7"
   },
   "source": [
    "train.shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmcrFIlc17pi"
   },
   "source": [
    "Can use *info* nad *describe* functions for detailed statistics/information of the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4HrbcYPH1e8y"
   },
   "source": [
    "train.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xc0IfuSd1e_N"
   },
   "source": [
    "train.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8xz1jchOH58C"
   },
   "source": [
    "train.isnull()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HSl4iq0cZYOc"
   },
   "source": [
    "# number of Null values per column\n",
    "train.isnull().sum()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2liwXNTL2Ox0"
   },
   "source": [
    "## Let's visualize the null values (need to get rid of them!)\n",
    "sns.heatmap(train.isnull())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g09pA_jS1fBp"
   },
   "source": [
    "# this heatmap function offers some additional features (cmap)\n",
    "sns.heatmap(train.isnull(), yticklabels=False, cmap='viridis' )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HkIkid_v1fEt"
   },
   "source": [
    "# can get rid of the color-bar if needed\n",
    "sns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis' )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CXmyMnl3OtT"
   },
   "source": [
    "- To conclude, we see that, for most of the dataframes, the Cabin info isn't present. Also for the Age column, a good amount data is absent\n",
    "- Let's remove the Cabin column and fill the missing values of the Age column"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VPE9EZGJyC_O"
   },
   "source": [
    "# Drop Cabin column\n",
    "train.drop('Cabin',axis=1, inplace = True) \n",
    "train.head()\n",
    "# axis = 1 represents columns. Learn more: https://www.w3resource.com/pandas/dataframe/dataframe-drop.php\n",
    "# The 'inplace' parameter modifies the actual memory instead of returning a copy. Learn more: https://www.ritchieng.com/pandas-inplace-parameter/"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yazE1Kh_3SvM"
   },
   "source": [
    "sns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis' ) # status after dropping the cabin column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dt3jlqH3--rZ"
   },
   "source": [
    "sns.countplot(x='Survived', data=train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hB1b9Vt1IC9S"
   },
   "source": [
    "# we can also add some styles to the graph...\n",
    "sns.set_style('whitegrid')  # reference: https://seaborn.pydata.org/generated/seaborn.set_style.html\n",
    "sns.countplot(x='Survived', data=train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s5NP1lTA3Sx0"
   },
   "source": [
    "# let's observe the relation of survived variable other variable\n",
    "sns.factorplot(x='Survived', col='Pclass', kind='count', data= train) # column names are case sensitive\n",
    "# females were given priority while saving pessengers. Thus more female survived than male passengers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SxJqs5ZWIiC9"
   },
   "source": [
    "# there are many other styles.. explore!\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x='Sex',hue='Survived', data=train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d9cC8vXe3S0S"
   },
   "source": [
    "sns.set_style('whitegrid') \n",
    "sns.countplot(x='Survived',hue='Pclass',data=train) \n",
    "# Passengers of class-3 has died the most :( )\n",
    "# Learn more about counterplots: https://seaborn.pydata.org/generated/seaborn.countplot.html"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "74Cr6u0BavoP"
   },
   "source": [
    "## survival vs dead per Pclass\n",
    "sns.set_style('whitegrid') \n",
    "sns.countplot(x='Pclass', hue='Survived', data=train)\n",
    "plt.title('Survived vs Dead according to passenger class')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "npqY2-v3IzOD"
   },
   "source": [
    "# these type of operations can be useful.\n",
    "train.groupby(['Sex']).Survived.sum()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VuiYkg95ZsD5"
   },
   "source": [
    "train.groupby(['Sex', 'Survived'])['Survived'].count()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uDN5NkU9dmZb"
   },
   "source": [
    "## check out the crosstab function!\n",
    "pd.crosstab([train.Sex,train.Survived],train.Pclass,margins=True).style.background_gradient(cmap='summer_r')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bvcHtXlEeCb1"
   },
   "source": [
    "# let's change the view by a little bit? which one looks better?  well it matters on the context!\n",
    "pd.crosstab([train.Sex,train.Pclass],train.Survived,margins=True).style.background_gradient(cmap='summer_r')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SYUBw6sIeCef"
   },
   "source": [
    "sns.factorplot('Pclass', 'Survived', data= train)\n",
    "plt.show()\n",
    "\n",
    "# passengers of class-3 survived the least! (Money.....)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4OrxFp1VfAfa"
   },
   "source": [
    "# how does it vary with gender??\n",
    "sns.factorplot('Pclass', 'Survived', hue='Sex', data= train)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfjwrtntfdb8"
   },
   "source": [
    "- From the FactorPlot and CrossTab categorical variables can easily be visualized. \n",
    "- Looking at the two plots, it is clear that women survival rate in Class 1 is about 95-96%, as only 3 out of 94 women died. So, it is now more clear that irrespective of Class, women are given first priority during Rescue. \n",
    "- Because survival rate for men in even Class 1 is also very low. From this conclusion, PClass is also a important feature."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "64Dst4YbJZR5"
   },
   "source": [
    "sns.violinplot(x='Sex', y='Age', hue='Survived', data=train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XESFy9uxJwQ1"
   },
   "source": [
    "# the split variable is handy!\n",
    "sns.violinplot(x='Sex', y='Age', hue='Survived', data=train, split=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yYfS0M6w3S24"
   },
   "source": [
    "# let's observe SibSp column (SibSp = Sibling or spouse)\n",
    "sns.countplot(x='SibSp', data= train)\n",
    "\n",
    "# seems like most of the passengers travelled alone... typical western culture"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Aclov9DfOXvk"
   },
   "source": [
    "sns.countplot(x='SibSp', hue = 'Survived', data= train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TJEdWZM6Kgj5"
   },
   "source": [
    "sns.distplot(train['Age'].dropna(), kde=False, color='green') #kde= False. helps to read the count"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7fu0GoPfLJmD"
   },
   "source": [
    "sns.distplot(train['Age'].dropna(), kde=True, color='green')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "doE69Emyvs_R"
   },
   "source": [
    "# the distplot function is similar to the histogram function on matplotlib...\n",
    "train['Age'].hist(bins=30,color = 'darkred', alpha=0.5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Ps0_j6IwMkM"
   },
   "source": [
    "train['Fare'].hist(bins=40, color='green')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TQlJvb8AANWI"
   },
   "source": [
    "## It is observed that there is a relation with Pclass and Age column.\n",
    "sns.boxplot(x='Pclass',y='Age', data=train, palette='winter')\n",
    "# we can find the average age for each Pclass. So in case of missing data, it can be replace with the avg."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D4vCGkKlDjeF"
   },
   "source": [
    "train.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wSdKTpj5ANYa"
   },
   "source": [
    "# Dealing with categorical values. Need to convert them into numbers\n",
    "Embarked = pd.get_dummies(train['Embarked'], drop_first=True) # 0 0 combination of Q-S column means C. Thus one feature is reduced.\n",
    "Embarked"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uq_98dbkANa9"
   },
   "source": [
    "gender = pd.get_dummies(train['Sex'], drop_first=True) # if male=0 it means female. Avoided one column by drop_first= True\n",
    "gender"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3a13RWhD3S5n"
   },
   "source": [
    "# Name, Ticket is not relevant to predint Survival. \n",
    "# Also, as we created dummies for gender and Embarked, we have to 'drop' the original column from the dataframe and concat them.\n",
    "train.drop(['Sex','Embarked','Name','Ticket'],axis=1, inplace=True) \n",
    "train.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vlly7cWnFrRQ"
   },
   "source": [
    "train=pd.concat([train,gen  der,Embarked],axis=1)\n",
    "train.head()\n",
    "# After dealing with missing values, replacing categorical values, Now the dataset is ready to pass into a model for prediction"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d8anPRSYFrWQ"
   },
   "source": [
    "sns.heatmap(train.isnull(), cmap='viridis')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QJPq_oUJLjNW"
   },
   "source": [
    "# lets fix the missing values of 'Age' feature. \n",
    "# policy, we'll replace it by the avg values of the corresponding pclass\n",
    "# credit: https://github.com/mohantyaditya/Exploratory-Data-Analysis-Titanic/blob/master/TitanicEda.ipynb\n",
    "def fix_missing_age(cols):\n",
    "    age = cols[0]\n",
    "    pclass = cols[1]\n",
    "\n",
    "    if pd.isnull(age):\n",
    "        if pclass==1:\n",
    "            return 38\n",
    "        elif pclass==2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 24\n",
    "    else:\n",
    "        return age"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c7E658w1LjQj"
   },
   "source": [
    "train['Age'] = train[['Age', 'Pclass']].apply(fix_missing_age, axis=1)\n",
    "sns.heatmap(train.isnull(), cmap='viridis')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GIBejtYIGwOb"
   },
   "source": [
    "# let's check the current status. (remember in the beginning there were lot's of missing values!)\n",
    "train.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqyyBcr1wvxP"
   },
   "source": [
    "## Building a Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xlj847CpN8cJ"
   },
   "source": [
    "train.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pXaOGF2iN8ea"
   },
   "source": [
    "# Need to drop the survived column since it's the class Label.\n",
    "train.drop('Survived', axis=1).head()  ## change is not happening in original place"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QpIKQ6oGN8g4"
   },
   "source": [
    "train['Survived'].head() ## change is not happening in original place"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wwX3Z9BgN8jn"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.drop('Survived', axis=1), \n",
    "                                                    train['Survived'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=101)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rIyzOBF8yoqz"
   },
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C6HaF5mLyotD"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l6or_A8eyovb"
   },
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u-BY9LK3GwTK"
   },
   "source": [
    "predictions = logmodel.predict(x_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "97VtwNZa1R7l"
   },
   "source": [
    "predictions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ou5v2PaT1R-D"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eN26BTEV8nHF"
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(accuracy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5gULmbtS1SAv"
   },
   "source": [
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "conf_mat"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UbjBouJD8nKC"
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_uLvV0EGrMf"
   },
   "source": [
    "- Not so bad! You might want to explore other feature engineering and the other titanic_text.csv file, some suggestions for feature engineering:\n",
    "\n",
    "- This was all for today. Although we filled the missing values of Age column, there are opportunities to do lot more 'feature engineering'  to find inner meanings.\n",
    "\n",
    "- There are lots of Notebooks in Kaggle website where you can find even deeper 'data analysis' on this dataset. Please explore!\n",
    "- Few of them are: [notebook by MANAV SEHGAL](https://www.kaggle.com/startupsci/titanic-data-science-solutions), [notebook by ASHWINI SWAIN](https://www.kaggle.com/ash316/eda-to-prediction-dietanic/notebook). (Find similar resources in the [here](https://www.kaggle.com/c/titanic/code), go to the 'code' tab, sort based on 'most votes'/'hotness'/there are other options...)\n",
    "\n",
    "## ***Some suggestions***:\n",
    "- Try grabbing the Title (Dr.,Mr.,Mrs,etc..) from the name as a feature\n",
    "- Maybe the Cabin letter could be a feature\n",
    "- Is there any info you can get from the ticket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7baUvaJIn2r"
   },
   "source": [
    "**Resources**:\n",
    "- [EDA on Titanic Dataset - Medium](https://medium.datadriveninvestor.com/step-by-step-exploratory-data-analysis-of-titanic-dataset-2d0fb09b0e86)\n",
    "-[EDA on Titanic Dataset - Jamil Moughal](https://www.kaggle.com/mjamilmoughal/eda-of-titanic-dataset-with-python-analysis)\n",
    "-[EDA + Logistic Regression on Titanic](https://github.com/krishnaik06/EDA1/blob/master/EDA.ipynb)"
   ]
  }
 ]
}