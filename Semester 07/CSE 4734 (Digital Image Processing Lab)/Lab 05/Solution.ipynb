{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhC_TZhOuzAJ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgvG73Myit8V"
   },
   "outputs": [],
   "source": [
    "def display_images(img_arr):\n",
    "    \"\"\" Displays a horizontal row of images. \"\"\"\n",
    "    f, axarr = plt.subplots(nrows=1, ncols=len(img_arr), figsize=(10, 10))\n",
    "    for i, img in enumerate(img_arr):\n",
    "        plt.sca(axarr[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img_arr[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd1BrWtBf3iT"
   },
   "source": [
    "## Task 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP3i8ZvSiMcO"
   },
   "source": [
    "To implement dilation, we go over the original image section by section and assign 1 (or 255) to sections which contain at least 1 non-zero pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0KbVBCcwoh2"
   },
   "outputs": [],
   "source": [
    "def dilation(image, SE_size):\n",
    "  m, n = image.shape\n",
    "  dilated_image = np.zeros((m,n))\n",
    "  for i in range(m - SE_size):\n",
    "    for j in range(n - SE_size):\n",
    "      crop = image[i:i+SE_size, j:j+SE_size]\n",
    "      if np.max(crop) != 0:\n",
    "        dilated_image[i + (SE_size // 2), j + (SE_size // 2)] = 255\n",
    "  \n",
    "  return dilated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi54r2VSieZE"
   },
   "source": [
    "The following section shows the results of applying dilation using a 9x9 structuring element on a 100x100 image. Note how the white section is significantly thicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "B5N4fU3bzVcK",
    "outputId": "a3fa3efa-30ea-4442-e55a-3292a8a22378"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0905(U).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (100, 100))\n",
    "dilated_image = dilation(image, 9)\n",
    "display_images([image, dilated_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6Cd4GtYmFkL"
   },
   "source": [
    "Next, we look into applying dilation repeatedly. A structuring element of size 5x5 was used in this case. As we apply dilation more times, the white portion becomes increasingly thicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "YQseYD6r8S_B",
    "outputId": "df476f37-41de-486f-f1d8-7b89f40147a8"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "image = cv2.imread('/content/FigP0905(U).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (100, 100))\n",
    "images.append(image)\n",
    "dilated_image = dilation(image, 5)\n",
    "images.append(dilated_image)\n",
    "dilated_image = dilation(dilated_image, 5)\n",
    "images.append(dilated_image)\n",
    "dilated_image = dilation(dilated_image, 5)\n",
    "images.append(dilated_image)\n",
    "display_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxlmDsF3mWPw"
   },
   "source": [
    "Unlike dilation, erosion requires the entire structuing element to be contained insider the object to be eroded. From a code perspective, this means that the section we are working with must not contain any zeroes. If this is true, only then can the resulting image have a 1 (or 255) at the central pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQM5F9qHzXeV"
   },
   "outputs": [],
   "source": [
    "def erosion(image, SE_size):\n",
    "  m, n = image.shape\n",
    "  eroded_image = np.zeros((m,n))\n",
    "  for i in range(m - SE_size):\n",
    "    for j in range(n - SE_size):\n",
    "      crop = image[i:i+SE_size, j:j+SE_size]\n",
    "      if np.all(crop):\n",
    "        eroded_image[i + (SE_size // 2), j + (SE_size // 2)] = 255\n",
    "  return eroded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0gkkG9OmyUy"
   },
   "source": [
    "Erosion on a 100x100 image using a 9x9 structuring element gives the following result. Notice how the white portion becomes thinner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "YRLqQdDW6wK3",
    "outputId": "87a5c4b6-c8f4-44a5-bd1b-fe95bb22ba1a"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0905(U).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (100, 100))\n",
    "eroded_image = erosion(image, 9)\n",
    "display_images([image, eroded_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmKHMyG8m5vs"
   },
   "source": [
    "Repeating the erosion process using a structuring element of size 5x5 shows that the white portion becomes increasingly thinner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "PkVgK6h08PN7",
    "outputId": "edb15244-8815-420b-8443-abc1874c18fd"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "image = cv2.imread('/content/FigP0905(U).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (100, 100))\n",
    "images.append(image)\n",
    "eroded_image = erosion(image, 5)\n",
    "images.append(eroded_image)\n",
    "eroded_image = erosion(eroded_image, 5)\n",
    "images.append(eroded_image)\n",
    "eroded_image = erosion(eroded_image, 5)\n",
    "images.append(eroded_image)\n",
    "display_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewOd898_ncLs"
   },
   "source": [
    "## Task 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "dA0RtG8v6zW2",
    "outputId": "6f04258a-d55a-4da7-a954-65be4bbfc7fe"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/Fig0941(a)(wood_dowels).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (300, 300))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v0t4kyrpBIq"
   },
   "source": [
    "Before trying to find the sizes of the granules, it is required that we apply a smoothing operation. A morphological smoothing operation is thus performed, which invovles an opening operation followed by a closing  operation. A 5x5 square kernel was chosen for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKRoGk21pc4o"
   },
   "outputs": [],
   "source": [
    "def smooth(image):\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "  image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "  image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usvi88Pnn92l"
   },
   "source": [
    "To determine the sizes of the granules in the image, we must apply the opening operation on the image repeatedly, with an increasing kernel size. An image of size 300x300 is being used.\n",
    "\n",
    "Using a circular kernel to apply the opening operation will cause the granules to become smaller and intensity to decrease. At the point when the kernel size is exacltly 1px more than some granule's size, that granule will disappear. This disappearance will cause a noticeable drop in intensity, which we can observe using the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-HQ9LyoraBe"
   },
   "outputs": [],
   "source": [
    "def granulometry(image):\n",
    "  image = smooth(image)\n",
    "  intensities = []\n",
    "  for i in range(1, 30):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (i, i))\n",
    "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    intensities.append(np.average(opening))\n",
    "  plt.plot(np.arange(len(intensities)), intensities, color =\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "hUp5BnSgrgre",
    "outputId": "af496863-ac35-4b3e-f5c4-efa692bd59e4"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/Fig0941(a)(wood_dowels).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (300, 300))\n",
    "granulometry(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYoTC0i0punV"
   },
   "source": [
    "Notice how there is a large drop at the x-axis values of 15 and 25. This means that the kernel sizes were 16 and 26 respectively at those points, which in turn means that the actual granules were of 15x15 pixels and 25x25 pixels respectively.\n",
    "\n",
    "It should be noted that these values are dependent on the image size. Images resized to different dimensions will give different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvtVO61OwCyH"
   },
   "source": [
    "## Task 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yEP53OtwHtN"
   },
   "source": [
    "This task requires us to answer the questions from exercise 9.34.\n",
    "\n",
    "Textural segmentation allows us to find a boundary between structures of two distinct sizes in a single image. Since the image shown below seperates granules of different sizes into distinct sections, textural segmentation will work. The fact that the sections are circular will make no difference to the ability of textural segmentation to find the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "tIXAPLZf_SkX",
    "outputId": "e9fa45a6-13ea-4711-b074-4fc89bac1451"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0934(blobs_in_circular_arrangement).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (300, 300))\n",
    "retVal, image = cv2.threshold(image, 155, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W210xWDAw8U1"
   },
   "source": [
    "The first step to performing textural segmentation is to perform a closing operation. The purpose is to make the entire section of smaller granules disappear, leaving a white background. This means we need to use circular kernels. The size of the kernels was found using trial and error, and a size of 25x25 was found to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "-jmnab6yrHF0",
    "outputId": "29191ade-7650-4959-88b9-a4742c25181f"
   },
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25))\n",
    "image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2tRL7VkxN4_"
   },
   "source": [
    "The second step is to perform an opening operation with a kernel of a size equal to the largest gap between the remaining granules. This also invovled trial and error, but a kernel size of 50x50 was found to work well. Performing the opening operation with this kernel dilates the larger granules so that they fill the entire region, leaving a black area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "mBYRdZLfr_4W",
    "outputId": "63cd33ff-c72d-4f34-bed5-d94f5dc4c446"
   },
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50))\n",
    "image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxNkMj0DxwQD"
   },
   "source": [
    "Since we now have two distinct regions, one white and one black, we can find the boundary between them using a morphological gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ZI1uWS2Pswe8",
    "outputId": "b620ca05-fac0-4a61-f2b4-0f66e75c2927"
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "gradient = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n",
    "plt.imshow(gradient, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8Dx0poqx6YV"
   },
   "source": [
    "Finally, we can perform a binary AND operation with the inverted gradient and the original image to get an image with a black boundary dividing the granules of the two sizes.\n",
    "\n",
    "The inverted gradient was used because the original gradient was a white line and the background of the image is also white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "lvVQFrImuB2o",
    "outputId": "3685c4fc-7a37-476d-bf10-e953e08546ef"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0934(blobs_in_circular_arrangement).tif', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (300, 300))\n",
    "retVal, image = cv2.threshold(image, 155, 255, cv2.THRESH_BINARY)\n",
    "image = cv2.bitwise_and(image, ~gradient)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ex13k0CyOO8"
   },
   "source": [
    "## Task 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "HSKIXCgNuUUH",
    "outputId": "3d4e029c-9fe3-40b1-939a-f2b51ea2d2a6"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0936(bubbles_on_black_background).tif', cv2.IMREAD_GRAYSCALE)\n",
    "retVal, image = cv2.threshold(image, 155, 255, cv2.THRESH_BINARY)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vstf2_nYLdLz"
   },
   "source": [
    "To obtain the particles connected to the boundary, we can just take the connected component that starts at the (0, 0) index.\n",
    "\n",
    "Unfortunately, the bottom border along with the particles connected to the bottom border is disconnected from the top border. As a workaround, the image is flipped, the component starting at (x, 0) is obtained and flipped again, and finally the union of the two outputs is taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "sxSy35t358bK",
    "outputId": "1c92a696-5a75-4c14-e8f0-c5c2de18f457"
   },
   "outputs": [],
   "source": [
    "total_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=4)\n",
    "\n",
    "for i in range(1, total_labels):\n",
    "  x = stats[i, cv2.CC_STAT_LEFT]\n",
    "  y = stats[i, cv2.CC_STAT_TOP]\n",
    "  w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "  h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "  area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "  if x == 0 and y == 0:\n",
    "    top_border = (labels == i).astype(\"uint8\") * 255\n",
    "    \n",
    "total_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(cv2.flip(image, 0), connectivity=4)\n",
    "for i in range(1, total_labels):\n",
    "  x = stats[i, cv2.CC_STAT_LEFT]\n",
    "  y = stats[i, cv2.CC_STAT_TOP]\n",
    "  w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "  h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "  area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "  if y == 0:\n",
    "    bottom_border = (labels == i).astype(\"uint8\") * 255\n",
    "    \n",
    "boundary_image = cv2.bitwise_or(top_border, cv2.flip(bottom_border, 0))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(boundary_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEWsc2saL7c8"
   },
   "source": [
    "If we read the original image again and remove the boundary particles, we will only be left with the overlapping and non-overlapping particles. If we retrieve all the connected components from these particles, we can then seperate out just the particles that are larger than a fixed size (400 px in area), the size of each of the non-overlapping particles. This size is unknown, so some trial and error was required to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "FZDwUBTYI7v-",
    "outputId": "72ccb0d3-8c14-4e3b-94e3-7f6aa36c2694"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0936(bubbles_on_black_background).tif', cv2.IMREAD_GRAYSCALE)\n",
    "retVal, image = cv2.threshold(image, 155, 255, cv2.THRESH_BINARY)\n",
    "image = image - boundary_image\n",
    "\n",
    "total_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=4)\n",
    "\n",
    "components = []\n",
    "for i in range(1, total_labels):\n",
    "  x = stats[i, cv2.CC_STAT_LEFT]\n",
    "  y = stats[i, cv2.CC_STAT_TOP]\n",
    "  w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "  h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "  area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "  if area > 400:\n",
    "    component = (labels == i).astype(\"uint8\") * 255\n",
    "    components.append(component)\n",
    "\n",
    "overlap = cv2.bitwise_or(components[0], components[1], 0)\n",
    "for i in range(2, len(components)):\n",
    "  overlap = cv2.bitwise_or(components[i], overlap, 0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(overlap, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCeOFX7kMlyA"
   },
   "source": [
    "Finally, we can remove both the bounday particles and the overlapping particles from the original image to obtain the non-overlapping particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "HY8I0ZrXMdmN",
    "outputId": "b59bfcba-2347-460d-f727-20f8aa6f0a0b"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/FigP0936(bubbles_on_black_background).tif', cv2.IMREAD_GRAYSCALE)\n",
    "retVal, image = cv2.threshold(image, 155, 255, cv2.THRESH_BINARY)\n",
    "image = image - boundary_image\n",
    "image = image - overlap\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
